---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Lab 2'
geometry: margin=1in
author: "Nathan Martinez, Haile Bizunehe, Hannah George, and Meera Sharma"
date: "2022-11-01"
output:
  pdf_document:
    toc: true
    number_sections: true
---

```{r load packages, echo = FALSE, message = FALSE, warning=FALSE}
list.of.packages <- c("tidyverse", "tsibble", "latex2exp", "fpp3", "tseries", "fable", "gridExtra", "MASS", "patchwork", "forecast", "lubridate", "feasts", "lmtest", "aTSA")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(tidyverse)
library(tsibble)
library(latex2exp)
library(fpp3)
library(tseries) 
library(fable)
library(gridExtra)
library(MASS)
library(patchwork)
library(forecast)
library(lubridate)
library(feasts)
library(lmtest)
library(aTSA)

theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

\newpage

<!---
# The Keeling Curve

In the 1950s, the geochemist Charles David Keeling observed a seasonal pattern in the amount of carbon dioxide present in air samples collected over the course of several years. He was able to attribute this pattern to the variation in global rates of photosynthesis throughout the year, caused by the difference in land area and vegetation cover between the Earth's northern and southern hemispheres. 

In 1958 Keeling began continuous monitoring of atmospheric carbon dioxide concentrations from the Mauna Loa Observatory in Hawaii and soon observed a trend increase carbon dioxide levels in addition to the seasonal cycle. He was able to attribute this trend increase to growth in global rates of fossil fuel combustion. This trend has continued to the present, and is known as the "Keeling Curve."

```{r plot the keeling curve, echo = FALSE, fig.align='center', fig.height=4, fig.width=10}
tsibble::as_tsibble(co2) %>%
  ggplot() + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$)'),
    subtitle = 'The "Keeling Curve"',
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
```


# Your Assignment 

Your goal in this assignment is to produce a comprehensive analysis of the Mona Loa CO2 data that you will be read by an interested, supervising data scientist. Rather than this being a final report, you might think of this as being a contribution to your laboratory. You and your group have been initially charged with the task of investigating the trends of global CO2, and told that if you find "anything interesting" that the team may invest more resources into assessing the question. 

Because this is the scenario that you are responding to: 

1. Your writing needs to be clear, well-reasoned, and concise. Your peers will be reading this, and you have a reputation to maintain.
2. Decisions that you make for your analysis need also be clear and well-reasoned. While the main narrative of your deliverable might only present the modeling choices that you determine are the most appropriate, there might exist supporting materials that examine what the consequences of other choices would be. As a concrete example, if you determine that a series is an AR(1) process your main analysis might provide the results of the critical test that led you to that determination and the results of the rest of the analysis under AR(1) modeling choices. However, in an appendix or separate document that is linked in your main report, you might show what a MA model would have meant for your results instead.
3. Your code and repository are a part of the deliverable. If you were to make a clear argument that this is a question worth pursuing, but then when the team turned to continue the work they found a repository that was a jumble of coding idioms, version-ed or outdated files, and skeletons it would be a disappointment.
-->

# Report from the Point of View of 1997 
<!--
For the first part of this task, suspend reality for a short period of time and conduct your analysis from the point of view of a data scientist doing their work in the early months of 1998. Do this by using data that is included in _every_ R implementation, the `co2` dataset. This dataset is lazily loaded with every R instance, and is stored in an object called `co2`. 
-->

## (3 points) Task 0a: Introduction
<!--
Introduce the question to your audience. Suppose that they _could_ be interested in the question, but they don't have a deep background in the area. What is the question that you are addressing, why is it worth addressing, and what are you going to find at the completion of your analysis. Here are a few resource that you might use to start this motivation. 

- [Wikipedia](https://en.wikipedia.org/wiki/Keeling_Curve)
- [First Publication](./background/keeling_tellus_1960.pdf)
- [Autobiography of Keeling](./background/keeling_annual_review.pdf)
-->

\hrulefill

Global temperatures are rising at a steady and alarming rate. This phenomenon is commonly referred to as climate change and it has been linked to anthropogenic emissions - greenhouse gas emissions associated with human activities like deforestation and the burning of fossil fuels. The climate change phenomenon has been well documented by notable researchers, including Charles David Keeling who is known for creating the Keeling Curve, a visualization that shows the change in the concentration of carbon dioxide in the Earthâ€™s atmosphere from 1959 to the present. We will use the same data that underpins the Keeling Curve to answer the following research questions: 1) How have carbon emissions increased over time? 2) What is the expected level of carbon emissions? To answer these research questions, we will apply time-series analysis to atmospheric C02 concentration data collected from Mauna Loa, Hawaii.  

Our team will construct a time-series model that shows how carbon emissions have increased over the past 38 years. More importantly, we will predict how much we should expect carbon emissions to rise if nothing is done to reduce anthropogenic emissions. These findings will be important because increasing carbon emissions have the potential to threaten our way of life, resulting in higher temperatures, rising sea levels, and increased frequency of extreme weather events, among other threats. We are hoping these findings will be used to develop company strategies and actions that will reduce our carbon footprint for the betterment of our planet. We also hope these findings will be used to encourage people at our company to take measures that will reduce their carbon emission contributions.

## (3 points) Task 1a: CO2 data
<!--
Conduct a comprehensive Exploratory Data Analysis on the `co2` series. This should include (without being limited to) a [description of how, where and why ](https://gml.noaa.gov/ccgg/about/co2_measurements.html) the data is generated, a thorough investigation of the trend, seasonal and irregular elements. Trends both in levels and growth rates should be discussed (consider expressing longer-run growth rates as annualized averages).

What you report in the deliverable should not be your own process of discovery, but rather a guided discussion that you have constructed so that your audience can come to an understanding as succinctly and successfully as possible. This means that figures should be thoughtfully constructed and what you learn from them should be discussed in text; to the extent that there is _any_ raw output from your analysis, you should intend for people to read and interpret it, and you should write your own interpretation as well.
-->

\hrulefill

```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
co2 %>%
  as_tsibble() -> co2_ts

# Getting the overall CO2 values
value <- co2_ts$value

# Making four different plots for evaluation
par(mfrow=c(2,2), mar = c(4.1, 4.1, 3, 2))
plot(value, type = "l", col="orange2", main="CO2 time series",
     xlab="Time", ylab="CO2 rate")
pacf(value, col="gold3", main="PACF of CO2")
acf(value, col="darkorange2", main="ACF of CO2")
hist(value, main="CO2 Distribution",
     ylab = "Frequency", xlab="CO2")
```

The top-left plot shows the timeseries over the period Jan 1959 through Jan 1997. A linear trend and annual seasonality are evident in the plot. 

The top-right plot shows the ACF (autocorrelation function) of the series at lags of 1 month. The correlogram shows both a gradual decay, which is a sign of a existance of a trend, and annual seasonality, shown by the spikes occuring every 12 months. 

The bottom-left plot shows the PACF (partial autocorrelation function) of the series. The PACF also suggests some seasonality, due to the oscillating significant spikes at various lags. The PACF shows lags 1, 2, 12, and 13 to be significant. The high significance at different lag on the PACF might suggest that it is an ARMA process. 

Lastly, the bottom-right plot shows the histogram of the data and helps us understand its spread. The distribution has close to a uniform distribution, which is not ideal for asympototic confidence interval estimation (requires normality in the distribution of residuals). 

## (3 points) Task 2a: Linear time trend model
<!--
Fit a linear time trend model to the `co2` series, and examine the characteristics of the residuals. Compare this to a quadratic time trend model. Discuss whether a logarithmic transformation of the data would be appropriate. Fit a polynomial time trend model that incorporates seasonal dummy variables, and use this model to generate forecasts to the year 2020. 
-->
\hrulefill

```{r linear time trend model}
as_tsibble(co2) -> co2_ts

co2_ts %>%
  model(TSLM(value ~ trend())) -> fit_co2_trend
```

```{r, echo=FALSE, results='hide'}
report(fit_co2_trend)
```

The linear time trend models estimates an increase of 0.11 in CO2 levels per month. The model residuals are shown below. 

```{r linear time trend model residuals, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
fit_co2_trend %>%
  gg_tsresiduals()
```

The timeseries in the top panel show the seasonality in the residuals, meaning we need to adjust the model for seasonal effects. Additionally, the U-shape of the residuals against the time index suggests non-linearity in the underlying process: a polynomial trend model may be need to capture this shape. The seasonality in the data is reflected in the ACF, which shows oscillating significant lags. The histogram of the residuals is normally distributed.

Note that we have not shown the Dickey-Fuller test here since the plot shows the series as being non-stationary. We have used the test later in the report when the plots are not very obvious in display stationarity in the series. 


```{r quadratic time trend model}
co2_ts %>%
  model(TSLM(value ~ trend()+ I(trend()^2))) -> fit_co2_quad_trend
```

```{r, echo=FALSE, results='hide'}
report(fit_co2_quad_trend)
```

```{r quadratic time trend model residuals, echo=FALSE, fig.align='center', fig.width=10, fig.height=4}
fit_co2_quad_trend %>%
  gg_tsresiduals()
```


The quadratic model is able to capture some of the non-linearity in the data, reducing the exaggerated U-shape in the residuals in the top panel. The trend is not completely modeled and we will require a polynomial term to capture the trend. The corresponding ACF still shows seasonal effects in the data. The histogram of the residuals is normal.

The variance in the data is not increasing at higher values, meaning we do not need a log-transformation. 

```{r quadratic time trend with season model}
co2_ts %>%
  model(TSLM(value ~ trend() + I(trend()^2) + I(trend()^3) + 
               season())) -> fit_co2_full_trend
```

```{r, echo=FALSE, results='hide'}
report(fit_co2_full_trend)
```

```{r quadratic time trend with season model residuals, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
fit_co2_full_trend %>%
  gg_tsresiduals()
```

Using seasonality and polynomial time trend, we are able to remove the seasonality and non-linearity from the residuals: note the ACF does not show oscillating significant lags. However, we still have a case of heteroskedasticity in the residuals, shown by the non-constant variance in the top panel. The histogram shows normally distributed residuals. 


```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
fc_co2_2020 <- fabletools::forecast(fit_co2_full_trend, h=276)

fc_co2_2020 %>%
  autoplot(co2_ts) +
  labs(
    title = "Forecasts of CO2 level Up To 2020 Using Regression",
    y = "CO2 Level", x = "Time"
  )
```

The seasonality and polynomial time trend model produces forecasts that extrapolate the linear trend of the series and include the seasonality of the data. However, as noted in the sections above, the residuals of this model do not represent white noise. Hence, a better model may be possible for this data. 
  

## (3 points) Task 3a: ARIMA times series model 

<!--
Following all appropriate steps, choose an ARIMA model to fit to the series. Discuss the characteristics of your model and how you selected between alternative ARIMA specifications. Use your model (or models) to generate forecasts to the year 2022. 
-->
\hrulefill

```{r plot first diff CO2 level, echo=FALSE, fig.align='center', fig.height=6, fig.width=10}
# Getting the differenced values
diff_level <- diff(co2_ts$value, lag=1)

# Making six different plots for evaluation
par(mfrow=c(3,2), mar = c(4.1, 4.1, 3, 2))
plot(diff_level, type = "l", col="orange2", main="Time series of first-order differenced data")
pacf(diff_level, col="gold3", main="PACF for first-order differenced data")
acf(diff_level, col="darkorange2", main="ACF for first-order differenced data")
hist(diff_level, main="First-order differenced Data Distribution")
```

In Task 1a, we determined that the time series is not stationary. First-order differencing, performed above, removes the non-seasonal trend from the series. However, the plots above show seasonality: the ACF shows oscillating correlations every 12 months, implying seasonality. To create a stationary timeseries, we need to add in seasonal differencing: 

```{r plot second diff CO2 level, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
# Getting the differenced CO2 levels; first and seasonal differecing
diff_level <- diff(diff(co2_ts$value, lag=1), lag=12)

# Making four different plots for evaluation
par(mfrow=c(2,2), mar = c(4.1, 4.1, 3, 2))
plot(diff_level, type = "l", col="orange2", main="Time series of first-order (and seasonal) differenced data ")
pacf(diff_level, col="gold3", main="PACF for first-order (and seasonal) differenced data")
acf(diff_level, col="darkorange2", main="ACF for first-order (and seasonal) differenced data")
hist(diff_level, main="Distribution for first-order (and seasonal) differenced data")
```

```{r adf test after first differencing and lag-12 differencing}
tseries::adf.test(diff(diff(co2_ts$value), lag=12),
         alternative = "stationary", k = 3)
```

The Dickey-Fuller test, for the first-order differenced (seasonal as well as non-seasonal) series, rejects the null hypothesis (which states that the time series is not stationary). The time series plot (upper-left panel) appears to be stationary as well. Significant correlations at different lags on both ACF and PACF suggest that the process is ARMA. The differenced-data distribution is normal; this will help in constructing asymptotic confidence intervals. Next, we will search for a model that minimizes AICc after applying first-order seasonal and non-seasonal differencing.

```{r}
model.aicc <- co2_ts %>%
  model(ARIMA(value ~ 0 + pdq(0:10, 1, 0:10) + PDQ(0:10, 1, 0:10),
                       ic="aicc", stepwise=F, greedy=F))
```

```{r, echo=FALSE, results='hide'}
model.aicc %>% report()
```

```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
model.aicc %>% gg_tsresiduals()
```

```{r}
resid.ts <- model.aicc %>%
  augment() %>%
  dplyr::select(.resid) %>%
  as.ts()

Box.test(resid.ts, lag = 1, type = "Ljung-Box")
Box.test(resid.ts, lag = 10, type = "Ljung-Box")
```

After performing first and seasonal differencing, we searched for the number of AR and MA terms for both seasonal and non-seasonal parts of the SARIMA model that minimizes AICc. We found a model with three non-seasonal MA terms, one seasonal AR term, and two seasonal MA terms that can better fit the data. We also examined the residuals, which show no systematic relationships and it has only one minor significant correlation. The Box-Ljung test also shows that the null hypothesis, which is that data are independently distributed, is not rejected. So we can say that the residuals are white noise.

```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
fc_co2_2022 <- fabletools::forecast(model.aicc, h=276)

fc_co2_2022 %>%
  autoplot(co2_ts) +
  labs(
    title = "Forecasts of CO2 level Up To 2022 using ARIMA model",
    y = "CO2 Level", x = "Time"
  )
```

The ARIMA does a reasonable job of predicting the trend and seasonality. Comparing it with the actual observed values will be helpful in evaluating if the model is useful. Compared to the linear regression forecast, the ARIMA model has a wider confidence interval.

## (3 points) Task 4a: Forecast atmospheric CO2 growth 
<!--
Generate predictions for when atmospheric CO2 is expected to be at [420 ppm](https://research.noaa.gov/article/ArtMID/587/ArticleID/2764/Coronavirus-response-barely-slows-rising-carbon-dioxide) and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2100. How confident are you that these will be accurate predictions?
-->
\hrulefill


```{r prediction, echo=FALSE}
fc_100_years <- fabletools::forecast(model.aicc, h=1236) %>%
  hilo() %>%
  unpack_hilo(c(`80%`, `95%`))

fc_100_years %>%
  filter(.mean >= 420 & .mean < 421) -> fc_420

fc_100_years %>%
  filter(.mean >= 500 & .mean < 501) -> fc_500
```

The code for calculating the following values has been excluded for brevity. Please refer to the Rmd file to see how they were calculated.

```{r, echo=FALSE}
# 420 PPM levels for the first and last time
fc_420_first <- head(fc_420, n =1)
fc_420_last  <- tail(fc_420, n =1)

fc_420_first_time  <- fc_420_first$index
fc_420_first_lower <- round(fc_420_first$`95%_lower`, 2)
fc_420_first_upper <- round(fc_420_first$`95%_upper`, 2)
fc_420_first_mean  <- round(fc_420_first$.mean, 2)

fc_420_last_time  <- fc_420_last$index
fc_420_last_lower <- round(fc_420_last$`95%_lower`, 2)
fc_420_last_upper <- round(fc_420_last$`95%_upper`, 2)
fc_420_last_mean  <- round(fc_420_last$.mean, 2)

# 500 PPM levels for the first and last time
fc_500_first <- head(fc_500, n =1)
fc_500_last  <- tail(fc_500, n =1)

fc_500_first_time  <- fc_500_first$index
fc_500_first_lower <- round(fc_500_first$`95%_lower`, 2)
fc_500_first_upper <- round(fc_500_first$`95%_upper`, 2)
fc_500_first_mean  <- round(fc_500_first$.mean, 2)

fc_500_last_time  <- fc_500_last$index
fc_500_last_lower <- round(fc_500_last$`95%_lower`, 2)
fc_500_last_upper <- round(fc_500_last$`95%_upper`, 2)
fc_500_last_mean  <- round(fc_500_last$.mean, 2)

# Atmospheric CO2 levels in the year 2100
fc_2100  <- tail(fc_100_years, n =1)

fc_2100_lower <- round(fc_2100$`95%_lower`, 2)
fc_2100_upper <- round(fc_2100$`95%_upper`, 2)
fc_2100_mean  <- round(fc_2100$.mean, 2)
```

CO2 is expected to be at 420 ppm level for the first time on `r fc_420_first_time` with expected value of `r fc_420_first_mean` and `r fc_420_first_lower` - `r fc_420_first_upper` 95% confidence interval.

CO2 is expected to be at 420 ppm level for the last time on `r fc_420_last_time` with expected value of `r fc_420_last_mean` and `r fc_420_last_lower` - `r fc_420_last_upper` 95% confidence interval.

CO2 is expected to be at 500 ppm level for the first time on `r fc_500_first_time` with expected value of `r fc_500_first_mean` and `r fc_500_first_lower` - `r fc_500_first_upper` 95% confidence interval. 

CO2 is expected to be at 500 ppm level for the last time on `r fc_500_last_time` with expected value of `r fc_500_last_mean` and `r fc_500_last_lower` - `r fc_500_last_upper` 95% confidence interval.

By the end of 2100 year, the CO2 is expected to be at `r fc_2100_mean` ppm level with `r fc_2100_lower` - `r fc_2100_upper` 95% confidence interval.

\newpage

# Report from the Point of View of the Present 
<!--
One of the very interesting features of Keeling and colleagues' research is that they were able to evaluate, and re-evaluate the data as new series of measurements were released. This permitted the evaluation of previous models' performance and a much more difficult question: If their models' predictions were "off" was this the result of a failure of the model, or a change in the system? 
-->

## (1 point) Task 0b: Introduction 
<!--
In this introduction, you can assume that your reader will have **just** read your 1997 report. In this introduction, **very** briefly pose the question that you are evaluating, and describe what (if anything) has changed in the data generating process between 1997 and the present. 
-->
\hrulefill

In our original 1997 paper, we made several predictions on the expected level carbon emissions. Now that enough time has passed, we will evaluate the accuracy of those predictions using time series analysis and extrapolate from present data to make predictions about the future.


## (3 points) Task 1b: Create a modern data pipeline for Mona Loa CO2 data.
<!--
The most current data is provided by the United States' National Oceanic and Atmospheric Administration, on a data page [[here](https://gml.noaa.gov/ccgg/trends/data.html)]. Gather the most recent weekly data from this page. (A group that is interested in even more data management might choose to work with the [hourly data](https://gml.noaa.gov/aftp/data/trace_gases/co2/in-situ/surface/mlo/co2_mlo_surface-insitu_1_ccgg_HourlyData.txt).) 

Create a data pipeline that starts by reading from the appropriate URL, and ends by saving an object called `co2_present` that is a suitable time series object. 

Conduct the same EDA on this data. Describe how the Keeling Curve evolved from 1997 to the present, noting where the series seems to be following similar trends to the series that you "evaluated in 1997" and where the series seems to be following different trends. This EDA can use the same, or very similar tools and views as you provided in your 1997 report.
-->
\hrulefill

Below is our code to read in the data from the appropriate URL and perform minor transformations in order to get the data into a proper time series object.

```{r}
read.csv(
  url("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv"),
  skip = 52) %>%
  mutate(time_index = make_datetime(year, month)) %>%
  mutate(time_index = yearmonth(time_index)) %>%
  filter(year < 2021) %>%
  as_tsibble(index = time_index) -> co2_present
```

Now we will start our EDA of the present data.

```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
# Getting the overall CO2 values
value <- co2_present$average

# Making four different plots for evaluation
par(mfrow=c(2,2), mar = c(4.1, 4.1, 3, 2))
plot(value, type = "l", col="orange2", main="CO2 time series",
     xlab="Time", ylab="CO2 rate")
pacf(value, col="gold3", main="PACF of CO2")
acf(value, col="darkorange2", main="ACF of CO2")
hist(value, main="CO2 Distribution",
     ylab = "Frequency", xlab="CO2")
```

When looking at the present data, there is not a huge difference between how it looks now versus how it looked in 1997. The time series plot shows that the CO2 levels continued to grow - at perhaps a stepper level of growth than before. The most notable difference is the CO2 Distribution histogram. In 1997 the distribution appeared to be almost bimodal, whereas now the distribution looks more heavy-tailed, and extends to much higher levels than it did previously.


## (1 point) Task 2b: Compare linear model forecasts against realized CO2
<!--
Descriptively compare realized atmospheric CO2 levels to those predicted by your forecast from a linear time model in 1997 (i.e. "Task 2a"). (You do not need to run any formal tests for this task.) 
-->
\hrulefill

```{r, warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
forecast <- append(rep(NA, length=nrow(co2_present)-nrow(fc_co2_2020)),
                   fc_co2_2020$.mean)
data.frame(time_index = co2_present$time_index, Actuals = co2_present$average, 
           Forecast = forecast) %>%
  pivot_longer(cols=c('Actuals', 'Forecast')) -> lm_vs_actuals

lm_vs_actuals %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line() + 
  labs(y = 'CO2 Level', x = '', title = 'Linear Model Forecast vs Realized CO2') 

```

The linear model forecast did not correctly capture the trend of the realized CO2 levels. The forecast appears to predict a stabilization in the CO2 levels, whereas the actual CO2 level trend increased.


## (1 point) Task 3b: Compare ARIMA models forecasts against realized CO2  
<!--
Descriptively compare realized atmospheric CO2 levels to those predicted by your forecast from the ARIMA model that you fitted in 1997 (i.e. "Task 3a"). Describe how the Keeling Curve evolved from 1997 to the present. 
-->
\hrulefill

```{r, warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
forecast <- append(rep(NA, length=nrow(co2_present)-nrow(fc_co2_2022)),
                   fc_co2_2022$.mean)
data.frame(time_index = co2_present$time_index, Actuals = co2_present$average, 
           Forecast = forecast) %>%
  pivot_longer(cols=c('Actuals', 'Forecast')) -> arima_vs_actuals

arima_vs_actuals %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line() + 
  labs(y = 'CO2 Level', x = '', title = 'ARIMA Forecast vs Realized CO2') 
```

The ARIMA forecast is much closer to the realized CO2 levels than the Linear Model forecast. The only difference is that the ARIMA model appears to have forecasted a linear trend, while the realized CO2 levels followed an almost exponential growth.

## (3 points) Task 4b: Evaluate the performance of 1997 linear and ARIMA models 
<!--
In 1997 you made predictions about the first time that CO2 would cross 420 ppm. How close were your models to the truth? 

After reflecting on your performance on this threshold-prediction task, continue to use the weekly data to generate a month-average series from 1997 to the present, and compare the overall forecasting performance of your models from Parts 2a and 3b over the entire period. (You should conduct formal tests for this task.) 
-->
\hrulefill

### Evaluating 1997 Predictions

```{r}
# Max actual data from 1958 to 2020 
max_actual_row <- co2_present[which.max(co2_present$average),]
max_actual_date <- max_actual_row$time_index
max_actual_value <- max_actual_row$average

# Predicted values and date over the max actual
fc_100_years %>%
  filter(.mean >= max_actual_value) -> fc_417
fc_417_first <- head(fc_417, n =1)
fc_417_first_value <- fc_417_first$.mean
fc_417_first_time  <- fc_417_first$index

# Precited values on actual maximum date
fc_100_years %>%
  filter(index == max_actual_date) -> max_date_pred_values
pred_date_average <- round(max_date_pred_values$.mean, 2) 
pred_date_lower <- round(max_date_pred_values$`95%_lower`, 2)
pred_date_upper <- round(max_date_pred_values$`95%_upper`, 2)

# Difference between predicted and actual on max date
pred_act_diff <- max_actual_value - pred_date_average
```

We originally predicted that CO2 would cross the 420 ppm threshold for the first time on `r fc_420_first_time` with an expected value of `r fc_420_first_mean` with a 95% confidence interval between `r fc_420_first_lower` - `r fc_420_first_upper`. The maximum average monthly value to date is `r max_actual_value` on `r max_actual_date`. In our predictions, the nearest date with a value at or over `r max_actual_value` is `r fc_417_first_time`. Therefore, our predicted average CO2 values were approximately 10-years behind the actuals. When comparing our predicted values in `r max_actual_date` to the actual data, we observe an average predicted value of `r pred_date_average` with a 95% confidence interval between `r pred_date_lower` - `r pred_date_upper`. Although our predicted average value was lower than the actual by value by `r pred_act_diff` ppm, the actual value of `r max_actual_value` is between our 95% confidence interval `r pred_date_lower` - `r pred_date_upper`.

### Evaluating Linear Model Forecast

Now we will evaluate the accuracy of the Linear Model forecast created in Task 2a.

```{r, echo=FALSE}
# Collecting both forecasts and actuals in the same dataframe.
lm_forecast <- append(rep(NA, length = nrow(co2_present) - nrow(fc_co2_2020)),
                      fc_co2_2020$.mean)
arima_forecast <- append(rep(NA, length = nrow(co2_present) - nrow(fc_co2_2022)),
                         fc_co2_2022$.mean)
data.frame(time_index = co2_present$time_index, actuals = co2_present$average, 
           lm_forecast = lm_forecast, arima_forecast = arima_forecast) %>%
  filter(!is.na(lm_forecast), !is.na(arima_forecast)) %>%
  mutate(lm_error = lm_forecast - actuals,
         arima_error = arima_forecast - actuals) %>%
  as_tsibble(index=time_index) -> forecast_perf_df
```


```{r, warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
forecast_perf_df %>%
  ggplot(aes(x=time_index, y=lm_error)) +
    geom_line() +
    labs(y='Forecast Error', x='',
         title='Forecast Error Time Series') -> lm_ts_plot

forecast_perf_df %>%
  ACF(x=time_index, y=lm_error, lag_max = 300) %>%
  autoplot() +
    labs(y = 'ACF', x = 'Lag (1 Month)', title = 'ACF') +
    scale_x_continuous(breaks = seq(0, 365, by = 50)) -> lm_acf_plot

forecast_perf_df %>%
  PACF(x=time_index, y=lm_error, lag_max = 50) %>%
  autoplot() +
    labs(y = 'PACF', x = 'Lag (1 Month)', title = 'PACF') -> lm_pacf_plot

forecast_perf_df %>%
  ggplot(aes(x=lm_error)) +
    geom_histogram(bins=50) +
    labs(y= 'Count', x='Forecast Error Size',
         title='Histogram') -> lm_hist_plot

lm_ts_plot / 
  (lm_acf_plot | lm_pacf_plot | lm_hist_plot) +
  plot_annotation(
    title = 'Linear Model Forecast Evaluation'
  )

```

The time series plot of the forecast errors steadily increases in magnitude as the forecast lead time increases. Based on the negative values, we can tell that the linear model under forecasted. This is also clear in the 2b plot. The ACF plot shows significant autocorrelation of forecast errors for multiple time periods, demonstrating a lack of the forecast capturing specific elements of the realized CO2 levels time series. The histogram is long-tailed in the negative errors, again, demonstrating that the Linear Model under-forecasted.

Now, we will take a look at some of the forecast accuracy metrics.

```{r polynomial time trend with season model present}
train_data <- co2_present %>% filter(year < 1998)
test_data <- co2_present %>% filter(year >= 1998)

# Build the same model as before.
train_data %>%
  model(TSLM(average ~ trend() + I(trend()^2) + I(trend()^3) + season())) -> lm_present_fit

lm_present_forecast <- fabletools::forecast(lm_present_fit, h=276)
fabletools::accuracy(lm_present_forecast, test_data)
```
Above, we can see various accuracy metrics that the Linear Model forecast was evaluated on. In particular, the RMSE value is 17.26 - this value makes sense given the error histogram maxed out at around -30. The MAPE stands at around 349% which is not a great value for such an clean time series.

### Evaluating ARIMA Forecast

Now we will evaluate the accuracy of the ARIMA forecast created in Task 3a.

```{r, warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
forecast_perf_df %>%
  ggplot(aes(x=time_index, y=arima_error)) +
    geom_line() +
    labs(y='Forecast Error', x='',
         title='Forecast Error Time Series') -> arima_ts_plot

forecast_perf_df %>%
  ACF(x=time_index, y=arima_error, lag_max = 300) %>%
  autoplot() +
    labs(y = 'ACF', x = 'Lag (1 Month)', title = 'ACF') +
    scale_x_continuous(breaks = seq(0, 365, by = 50)) -> arima_acf_plot

forecast_perf_df %>%
  PACF(x=time_index, y=arima_error, lag_max = 50) %>%
  autoplot() +
    labs(y = 'PACF', x = 'Lag (1 Month)', title = 'PACF') -> arima_pacf_plot

forecast_perf_df %>%
  ggplot(aes(x=arima_error)) +
    geom_histogram(bins=50) +
    labs(y= 'Count', x='Forecast Error Size',
         title='Histogram') -> arima_hist_plot

arima_ts_plot / 
  (arima_acf_plot | arima_pacf_plot | arima_hist_plot) +
  plot_annotation(
    title = 'ARIMA Forecast Evaluation'
  )
```
The time series plot of the forecast errors steadily increases in magnitude as the forecast lead time increases, however, the forecast error values are not as large as they are from the Linear Model forecast. The ARIMA model also under-forecasted based on the forecast error time series and the histogram. The ACF plot shows significant autocorrelation of forecast errors for multiple time periods, demonstrating a lack of the forecast capturing specific elements of the realized CO2 levels time series.

Now, we will take a look at some of the forecast accuracy metrics.

```{r, arima model with present data with same old model}
# Build the same model as before.
train_data %>%
  model(ARIMA(average ~ 0 + pdq(0, 1, 1) + PDQ(1, 1, 2))) -> arima_present_fit

arima_present_forecast <- fabletools::forecast(arima_present_fit, h=276)
fabletools::accuracy(arima_present_forecast, test_data)
```
The error metrics for the ARIMA model do appear to be much better than they were for the Linear Model. With the RMSE standing at 7.37 and the MAPE being 151%. There is still room for improvement in this model, but it is performing better than the linear model.


## (4 points) Task 5b: Train best models on present data
<!--
Seasonally adjust the weekly NOAA data, and split both seasonally-adjusted (SA) and non-seasonally-adjusted (NSA) series into training and test sets, using the last two years of observations as the test sets. For both SA and NSA series, fit ARIMA models using all appropriate steps. Measure and discuss how your models perform in-sample and (psuedo-) out-of-sample, comparing candidate models and explaining your choice. In addition, fit a polynomial time-trend model to the seasonally-adjusted series and compare its performance to that of your ARIMA model.
-->
\hrulefill

```{r, seasonally adjust data, echo=FALSE}
# Seasonally adjusted data
co2_sa <- co2_present %>%
  model(stl = STL(average)) %>%
  components() %>%
  as_tsibble()
```

Splitting both the SA and NSA time series into training and test sets.

```{r, test and train for 2 datasets, message=FALSE}
# Test size
test.size <- 24 # Months
test.df <- tail(co2_present, test.size) %>%
  mutate(.mean = average) # Used later for ggplot

# Train for non-seasonal (ns)
train_ns <- head(co2_present, nrow(co2_present) -  test.size)
           
# Train for seasonal (s)
train_s <- head(co2_sa, nrow(co2_sa) -  test.size) %>%
  subset(select=-c(.model))
```

### Training the ARIMA Model on the NSA Data

```{r}
tseries::adf.test(train_ns$average, alternative = "stationary")
```
The ADF test statistic and p-value come out to be equal to -0.72 and 0.96 respectively. Since the p-value is greater than 0.05, we would fail to reject the null hypothesis that the time series is non-stationary. Thus, we will apply differencing in order to attempt to make the time series stationary.

```{r, check differencing for ns model, warning=FALSE, echo=FALSE, fig.align='center', fig.height=2, fig.width=10}
# check the different values: 
ns_diff <- train_ns %>%
  mutate(first_diff_season = difference(average, differences = 1)) %>%
  mutate(second_diff = difference(average, 2)) 

# Plot & check
ns_diff %>%  
  ggplot(aes(x = time_index, y = first_diff_season)) +
  geom_line() +
  labs(title = "First Difference", x = "Time", y = "Residuals")
```

Based on the above plot, it would appear that the first difference appears to be stationary. We will verify with an ADF test.

```{r, warning=FALSE}
ns_diff_data <- train_ns %>%
  mutate(second_diff = difference(average, differences = 1)) %>%
  filter(!is.na(second_diff))
  
tseries::adf.test(ns_diff_data$second_diff, alternative = "stationary")
```

The ADF test statistic and p-value come out to be equal to -34.717 and 0.01, respectively. Since the p-value is less than 0.05, we would reject the null hypothesis that the time series is non-stationary. Because we know we should use first differencing, we will set these hyper parameters and then select a model with the lowest BIC.

```{r}
model.ns <- train_ns %>%
  model(ARIMA(average ~ 0 + pdq(0:10, 1, 0:10) + PDQ(0:10, 1, 0:10),
                       ic="bic", stepwise=F, greedy=F))
```

```{r, echo=FALSE, results='hide'}
model.ns %>%
  report()
```

```{r, echo=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
# Print residuals 
model.ns %>%
  gg_tsresiduals() +
  labs(title = "Non-seasonal ARIMA Plot")
```

The residual plots for the ARIMA model appear to have constant variance and a mean near zero. The histogram also appears to be normally distributed. 

```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}  
# Forecast over the entire period
fc_24_ns <- fabletools::forecast(model.ns, h = 24)

far_plot <- fc_24_ns %>%
  autoplot(train_ns) +
  labs(
    title = "ARIMA Forecast Using Non-Seasonally-Adjusted Present Data",
    y = "CO2 Level", x = ""
  )

near_plot <- ggplot(NULL, aes(x = time_index, y = .mean)) + 
  geom_line(data = fc_24_ns, col = "blue") +
  geom_line(data = test.df, col = "black") +
  labs(title = "Arima Forecast Vs. Actuals",
       subtitle = "Blue = Predicted", 
       x = "Time", 
       y = "CO2 Emissions")

grid.arrange(far_plot, near_plot, ncol=1)
```

The forecast plots seem to track nicely with the actuals for the 24 month period.


### Training the ARIMA Model on the SA Data

We will perform an ADF test to determine whether the seasonally-adjusted data is stationary.

```{r}
tseries::adf.test(train_s$season_adjust, alternative = "stationary")
```
The ADF test statistic and p-value come out to be equal to -0.33 and 0.9895 respectively. Since the p-value is greater than 0.05, we would fail to reject the null hypothesis that the time series is non-stationary. Thus, we will apply differencing in order to attempt to make the time series stationary.

```{r, check differencing for s model, warning=FALSE, echo=FALSE, fig.align='center', fig.height=2, fig.width=10}
# check the different values: 
s_diff <- train_s %>%
  mutate(second_diff = difference(season_adjust, 2))

# Plot & check
s_diff %>%  
  ggplot(aes(x = time_index, y = second_diff)) +
  geom_line() +
  labs(title = "Second Difference", x = "Time", y = "Residuals")
```
Based on the above plot, it would appear that the first difference appears to be stationary. We will verify with an ADF test.

```{r, warning=FALSE}
s_diff_data <- train_s %>%
  mutate(first_diff = difference(season_adjust, 2)) %>%
  filter(!is.na(first_diff))
  
tseries::adf.test(s_diff_data$first_diff, alternative = "stationary")
```
The ADF test statistic and p-value come out to be equal to -7.86 and 0.01 respectively. Since the p-value is less than 0.05, we could reject the null hypothesis that the time series is non-stationary.

Due to these results, we decided to use a second difference and a seasonal difference of 0, and we let the ARIMA function choose the remaining hyper parameters.  

```{r, warning=FALSE}
model.s <- train_s %>%
  model(ARIMA(season_adjust ~ 0 + pdq(0:10, 2, 0:10) + PDQ(0:10, 0, 0:10),
                       ic="bic", stepwise=F, greedy=F))
```

```{r, echo=FALSE, results='hide'}
model.s %>%
  report()
```

```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
# Print residuals 
model.s %>%
  gg_tsresiduals() + 
  labs(title = "Seasonal ARIMA Plot")
```
```{r, adj test for seasonal}
augment(model.s) %>%
  features(.innov, ljung_box, dof = 14, lag = 24)
```

```{r, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}  
# Forecast over the entire period
fc_24_s <- fabletools::forecast(model.s, h = 24)

far_plot_2 <- fc_24_s %>%
  autoplot(train_s) +
  labs(
    title = "ARIMA Forecast Using Seasonally-Adjusted Present Data",
    y = "CO2 Level", x = ""
  )

near_plot2 <- ggplot(NULL, aes(x = time_index, y = .mean)) + 
  geom_line(data = fc_24_s, col = "blue") +
  geom_line(data = test.df, col = "black") +
  labs(title = "Arima Model Vs. Actuals",
       subtitle = "Blue = Predicted", 
       x = "Time", 
       y = "CO2 Emissions")

grid.arrange(far_plot_2, near_plot2, ncol=1)

```

The ARIMA hyper parameters that were selected include the following: ARIMA(1,2,1)(4,0,0)[12]. Using these values, the residual plots appear to meet the condition of constant variance and a mean near zero. The test results also past the ljung_box statistical test. The ACF had some extreme values at the 2nd and 24th time lag, which seems a bit strange. The forecast estimates appear strange when juxtaposed next to the monthly data inclusive of the seasonal trends but that is because the underlying seasonality has been removed. 

### Training the Polynomial Time-Trend Model on the SA Data

```{r polynomial time trend with adjusted seaonal data}
# Build model
train_s %>%
  model(TSLM(season_adjust ~ trend() + I(trend()^2) + I(trend()^3))) -> fit_poly
```

```{r, echo=FALSE, results='hide'}
# Print model
report(fit_poly)
```

```{r polynomial based on underlying seasonal adjustments, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}
# Print results
fit_poly %>%
  gg_tsresiduals() +
  labs(title = "Residual Plots: Polynomial Model")
```

The residual diagnostic plots does not produce promising results. The residual time series does not have a constant variance or mean, and it is not clear that the mean is near zero. All values within the ACF exceed the threshold values and the histogram of the residuals appears to be skewed to the right. 

As a result, we have decided to go with the `ARIMA(1,1,1)(2,1,1)[12]` model because it adjusts for the underlying seasonality, which we may need to adjust going forward, all of its residual values are are within the acceptable bands of the ACF, and it is easier to explain the model results to a non-technical audience.


## (3 points) Task Part 6b: How bad could it get?
<!--
With the non-seasonally adjusted data series, generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2122. How confident are you that these will be accurate predictions?
-->
\hrulefill

We will now retrain the selected model on all of the available data.

```{r, arima model based on train data}
model.bic3 <- co2_present %>%
  model(ARIMA(average ~ 0 + pdq(1, 1, 1) + PDQ(2, 1, 1), ic="bic"))

# Prediction from 2021 to 2121
fc2_100 <- fabletools::forecast(model.bic3, h=1224) %>%
  hilo() %>%
  unpack_hilo(c(`80%`, `95%`))

fc2_100 %>%
  filter(.mean >= 420 & .mean < 421) -> fc2_420

fc2_100 %>%
  filter(.mean >= 500 & .mean < 501) -> fc2_500
```

The code for calculating the following values has been excluded for brevity. Please refer to the Rmd file to see how they were calculated.

```{r, prediction 420 ppm from 2021 on, echo=FALSE}
# 420 PPM levels for the first and last time
fc2_420_first <- head(fc2_420, n =1)
fc2_420_last  <- tail(fc2_420, n =1)

# Get values for 420 ppm predictions
fc2_420_first_time  <- fc2_420_first$time_index
fc2_420_first_lower <- round(fc2_420_first$`95%_lower`, 2)
fc2_420_first_upper <- round(fc2_420_first$`95%_upper`, 2)
fc2_420_first_mean  <- round(fc2_420_first$.mean, 2)

fc2_420_last_time  <- fc2_420_last$time_index
fc2_420_last_lower <- round(fc2_420_last$`95%_lower`, 2)
fc2_420_last_upper <- round(fc2_420_last$`95%_upper`, 2)
fc2_420_last_mean  <- round(fc2_420_last$.mean, 2)
```

Based on the findings from our model, we predict that CO2 will cross the 420 ppm threshold for the first time on `r fc2_420_first_time` with an expected value of `r fc2_420_first_mean` with a 95% confidence interval between `r fc2_420_first_lower` - `r fc2_420_first_upper`. Our model also predicts that the last time CO2 will be between the 420 and 421 ppm threshold will be on `r fc2_420_last_time` with an expected value of `r fc2_420_last_mean` with a 95% confidence interval between `r fc2_420_last_lower` - `r fc2_420_last_upper`.

```{r, prediction 500 ppm from 2021 on, echo=FALSE}
# 420 PPM levels for the first and last time
fc2_500_first <- head(fc2_500, n =1)
fc2_500_last  <- tail(fc2_500, n =1)

# Get values for 420 ppm predictions
fc2_500_first_time  <- fc2_500_first$time_index
fc2_500_first_lower <- round(fc2_500_first$`95%_lower`, 2)
fc2_500_first_upper <- round(fc2_500_first$`95%_upper`, 2)
fc2_500_first_mean  <- round(fc2_500_first$.mean, 2)

fc2_500_last_time  <- fc2_420_last$time_index
fc2_500_last_lower <- round(fc2_500_last$`95%_lower`, 2)
fc2_500_last_upper <- round(fc2_500_last$`95%_upper`, 2)
fc2_500_last_mean  <- round(fc2_500_last$.mean, 2)

```

Based on the findings from our model, we predict that CO2 will cross the 500 ppm threshold for the first time on `r fc2_500_first_time` with an expected value of `r fc2_500_first_mean` with a 95% confidence interval between `r fc2_500_first_lower` - `r fc2_500_first_upper`. Our model also predicts that the last time CO2 will be between the 500 and 501 ppm threshold will be on `r fc2_500_last_time` with an expected value of `r fc2_500_last_mean` with a 95% confidence interval between `r fc2_500_last_lower` - `r fc2_500_last_upper`.

```{r, prediction to 2122, echo=FALSE}
# Atmospheric CO2 levels in the year 2122
fc_2122  <- tail(fc2_100, n =1)

# Carbon values in 2122
fc_2122_lower <- round(fc_2122$`95%_lower`, 2)
fc_2122_upper <- round(fc_2122$`95%_upper`, 2)
fc_2122_mean  <- round(fc_2122$.mean, 2)
```

'By the end of 2122, our model predicts that CO2 will be `r fc_2122_mean` ppm with a 95% confidence interval between `r fc_2122_lower` - `r fc_2122_upper`. Although we are not very confident in the point estimate for the average CO2 emissions at the end of 2022, we are fairly confident (95%!) that average CO2 emissions will be between our confidence interval of  `r fc_2122_lower` - `r fc_2122_upper`. 





